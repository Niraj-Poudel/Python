{"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport tensorflow as tf\n\n'''Loding the fashion MNIST data directly from the tf.keras API'''\nmnist = tf.keras.datasets.fashion_mnist\n\n(training_images,training_labels),(test_images,test_labels) = mnist.load_data()\n\n'''Viewing the values that are stord in the dataset using numpy and matplotlib library'''\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nplt.imshow(training_images[0])\n#print(training_images[0])\n#print(test_images[0])\n\n'''The image values lies between 0 and 255. So first of all we have to convert these values from 0-255 to 0-1.'''\ntraining_images = training_images/255\ntest_images = test_images/255\n#print(training_images[0])\n\n'''Now lets design a model'''\nmodel = tf.keras.Sequential([tf.keras.layers.Flatten(),\n                            tf.keras.layers.Dense(128,activation=tf.nn.relu),\n                            tf.keras.layers.Dense(10,activation=tf.nn.softmax)])\n\n'''Sequential: That defines a SEQUENCE of layers in the neural network\n\nFlatten: Remember earlier where our images were a square, when you printed them out? Flatten just takes that square and turns it into a 1 dimensional set.\n\nDense: Adds a layer of neurons\n\nEach layer of neurons need an activation function to tell them what to do. There's lots of options, but just use these for now.\n\nRelu effectively means \"If X>0 return X, else return 0\" -- so what it does it it only passes values 0 or greater to the next layer in the network.\n\nSoftmax takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!'''\n\n\n'''Now compiling and fitting the model'''\nmodel.compile(optimizer = tf.optimizers.Adam(),\n              loss = 'sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(training_images, training_labels, epochs=5)\n\n'''Evaluating our model'''\nmodel.evaluate(test_images, test_labels)","metadata":{"collapsed":false,"_kg_hide-input":false},"execution_count":0,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}