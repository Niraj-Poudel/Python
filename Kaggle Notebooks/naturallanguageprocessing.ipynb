{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# What is Natural Language Processing?\n",
    "Natural Language Processing, usually shortened as NLP, is a branch of artificial intelligence that deals with the interaction between computers and humans using the natural language.\n",
    "The ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable.\n",
    "Most NLP techniques rely on machine learning to derive meaning from human languages.\n",
    "In fact, a typical interaction between humans and machines using Natural Language Processing could go as follows:\n",
    "1. A human talks to the machine\n",
    "2. The machine captures the audio\n",
    "3. Audio to text conversion takes place\n",
    "4. Processing of the text’s data\n",
    "5. Data to audio conversion takes place\n",
    "6. The machine responds to the human by playing the audio file\n",
    "\n",
    "# What is NLP used for?\n",
    "Natural Language Processing is the driving force behind the following common applications:\n",
    "1. Language translation applications such as Google Translate\n",
    "2. Word Processors such as Microsoft Word and Grammarly that employ NLP to check grammatical accuracy of texts.\n",
    "3. Interactive Voice Response (IVR) applications used in call centers to respond to certain users’ requests.\n",
    "4. Personal assistant applications such as OK Google, Siri, Cortana, and Alexa.\n",
    "\n",
    "\n",
    "# Why is NLP difficult?\n",
    "Natural Language processing is considered a difficult problem in computer science. It’s the nature of the human language that makes NLP difficult.\n",
    "The rules that dictate the passing of information using natural languages are not easy for computers to understand.\n",
    "Some of these rules can be high-leveled and abstract; for example, when someone uses a sarcastic remark to pass information.\n",
    "On the other hand, some of these rules can be low-levelled; for example, using the character “s” to signify the plurality of items.\n",
    "Comprehensively understanding the human language requires understanding both the words and how the concepts are connected to deliver the intended message.\n",
    "While humans can easily master a language, the ambiguity and imprecise characteristics of the natural languages are what make NLP difficult for machines to implement.\n",
    "\n",
    "# How does Natural Language Processing Works?\n",
    "NLP entails applying algorithms to identify and extract the natural language rules such that the unstructured language data is converted into a form that computers can understand.\n",
    "When the text has been provided, the computer will utilize algorithms to extract meaning associated with every sentence and collect the essential data from them.\n",
    "Sometimes, the computer may fail to understand the meaning of a sentence well, leading to obscure results.\n",
    "For example, a humorous incident occurred in the 1950s during the translation of some words between the English and the Russian languages.\n",
    "Here is the biblical sentence that required translation:\n",
    "\n",
    "“The spirit is willing, but the flesh is weak.” \n",
    "\n",
    "Here is the result when the sentence was translated to Russian and back to English:\n",
    "\n",
    "“The vodka is good, but the meat is rotten.” \n",
    "\n",
    "# What are the techniques used in NLP?\n",
    "Syntactic analysis and semantic analysis are the main techniques used to complete Natural Language Processing tasks.\n",
    "Here is a description on how they can be used.\n",
    "### Syntax\n",
    "Syntax refers to the arrangement of words in a sentence such that they make grammatical sense.\n",
    "In NLP, syntactic analysis is used to assess how the natural language aligns with the grammatical rules.\n",
    "Computer algorithms are used to apply grammatical rules to a group of words and derive meaning from them.\n",
    "Here are some syntax techniques that can be used:\n",
    "* Lemmatization *: It entails reducing the various inflected forms of a word into a single form for easy analysis.\n",
    "* Morphological segmentation: It involves dividing words into individual units called morphemes.\n",
    "* Word segmentation: It involves dividing a large piece of continuous text into distinct units.\n",
    "* Part-of-speech tagging: It involves identifying the part of speech for every word.\n",
    "* Parsing: It involves undertaking grammatical analysis for the provided sentence.\n",
    "* Sentence breaking: It involves placing sentence boundaries on a large piece of text.\n",
    "* Stemming: It involves cutting the inflected words to their root form.\n",
    "\n",
    "\n",
    "### Semantics\n",
    "Semantics refers to the meaning that is conveyed by a text. Semantic analysis is one of the difficult aspects of Natural Language Processing that has not been fully resolved yet.\n",
    "It involves applying computer algorithms to understand the meaning and interpretation of words and how sentences are structured.\n",
    "Here are some techniques in semantic analysis:\n",
    "* Named entity recognition (NER): It involves determining the parts of a text that can be identified and categorized       into preset groups. Examples of such groups include names of people and names of places.\n",
    "* Word sense disambiguation: It involves giving meaning to a word based on the context.\n",
    "* Natural language generation: It involves using databases to derive semantic intentions and convert them into human       language.\n",
    "\n",
    "\n",
    "https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Basic Natural Language Processing with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.book import*"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Counting vocabulary of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Wall Street Journal>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100676"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent1: Call me Ishmael .\n",
      "sent2: The family of Dashwood had long been settled in Sussex .\n",
      "sent3: In the beginning God created the heaven and the earth .\n",
      "sent4: Fellow - Citizens of the Senate and of the House of Representatives :\n",
      "sent5: I have a problem with people PMing me to lol JOIN\n",
      "sent6: SCENE 1 : [ wind ] [ clop clop clop ] KING ARTHUR : Whoa there !\n",
      "sent7: Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\n",
      "sent8: 25 SEXY MALE , seeks attrac older single lady , for discreet encounters .\n",
      "sent9: THE suburb of Saffron Park lay on the sunset side of London , as red and ragged as a cloud of sunset .\n"
     ]
    }
   ],
   "source": [
    "sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12408"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stockbrokers',\n",
       " 'Killeen',\n",
       " 'stretching',\n",
       " 'anecdotal',\n",
       " 'S&P',\n",
       " 'workable',\n",
       " 'photocopy',\n",
       " 'lender',\n",
       " 'Achievement',\n",
       " 'community']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(text7))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Frequency of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 4885, 'the': 4045, '.': 3828, 'of': 2319, 'to': 2164, 'a': 1878, 'in': 1572, 'and': 1511, '*-1': 1123, '0': 1099, ...})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = FreqDist(text7)\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4885"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq[',']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre', 'Vinken', ',', '61', 'years', 'old', 'will', 'join', 'the', 'board']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = freq.keys()\n",
    "list(key)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['billion',\n",
       " 'company',\n",
       " 'president',\n",
       " 'because',\n",
       " 'market',\n",
       " 'million',\n",
       " 'shares',\n",
       " 'trading',\n",
       " 'program']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqWords = [words for words in key if len(words)>5 and freq[words]>100]\n",
    "freqWords"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Normalization and stemming\n",
    "\n",
    "* Different forms of same 'words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go', 'go', 'going', 'goings', 'goes']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = 'Go go Going Goings Goes'\n",
    "word1 = input1.lower().split(' ')\n",
    "word1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go', 'go', 'go', 'go', 'goe']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "[porter.stem(i) for i in word1]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    " * Word that come out to be actually meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Universal', 'Declaration', 'of', 'Human', 'Rights', ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = nltk.corpus.udhr.words('English-Latin1')\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['univers',\n",
       " 'declar',\n",
       " 'of',\n",
       " 'human',\n",
       " 'right',\n",
       " 'preambl',\n",
       " 'wherea',\n",
       " 'recognit',\n",
       " 'of',\n",
       " 'the',\n",
       " 'inher',\n",
       " 'digniti',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'equal',\n",
       " 'and',\n",
       " 'inalien',\n",
       " 'right',\n",
       " 'of']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# still lematization\n",
    "[porter.stem(t) for t in corpus][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Universal',\n",
       " 'Declaration',\n",
       " 'of',\n",
       " 'Human',\n",
       " 'Rights',\n",
       " 'Preamble',\n",
       " 'Whereas',\n",
       " 'recognition',\n",
       " 'of',\n",
       " 'the',\n",
       " 'inherent',\n",
       " 'dignity',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'equal',\n",
       " 'and',\n",
       " 'inalienable',\n",
       " 'right',\n",
       " 'of']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WNlemma = nltk.WordNetLemmatizer()\n",
    "[WNlemma.lemmatize(t) for t in corpus[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey', 'whats', 'going', 'on.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tokenization\n",
    "text = 'hey whats going on.'\n",
    "text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey', 'whats', 'going', 'on', '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the first sentence.',\n",
       " 'A gallon of milk in the Nepal costs Rs.300.',\n",
       " 'Is this the third sentence?',\n",
       " 'Yes, it is!']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text12 = \"This is the first sentence. A gallon of milk in the Nepal costs Rs.300. Is this the third sentence? Yes, it is!\"\n",
    "sentences = nltk.sent_tokenize(text12)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Advanced Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## POS(Parts-Of-Speech) tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('MD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hey', 'NN'), ('whats', 'NNS'), ('going', 'VBG'), ('on', 'IN'), ('.', '.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text13 = nltk.word_tokenize(text)\n",
    "nltk.pos_tag(text13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chilling', 'VBG'),\n",
       " ('with', 'IN'),\n",
       " ('friends', 'NNS'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('fantastic', 'JJ'),\n",
       " ('feeling', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text14 = nltk.word_tokenize(\"Chilling with friends is a fantastic feeling.\")\n",
    "nltk.pos_tag(text14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Alice) (VP (V loves) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "# Parsing sentence structure\n",
    "text15 = nltk.word_tokenize(\"Alice loves Bob\")\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP\n",
    "NP -> 'Alice' | 'Bob'\n",
    "V -> 'loves'\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar)\n",
    "trees = parser.parse_all(text15)\n",
    "for tree in trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## POS tagging and Ambiguity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'), ('old', 'JJ'), ('man', 'NN'), ('the', 'DT'), ('boat', 'NN')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text18 = nltk.word_tokenize(\"The old man the boat\")\n",
    "nltk.pos_tag(text18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Colorless', 'NNP'),\n",
       " ('green', 'JJ'),\n",
       " ('ideas', 'NNS'),\n",
       " ('sleep', 'VBP'),\n",
       " ('furiously', 'RB')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text19 = nltk.word_tokenize(\"Colorless green ideas sleep furiously\")\n",
    "nltk.pos_tag(text19)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
